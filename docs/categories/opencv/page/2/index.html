<!DOCTYPE html>
<html lang="ja" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>OpenCV | MatLoverによるMatlab以外のブログ</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="https://opqrstuvcut.github.io/blog/categories/opencv/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://opqrstuvcut.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://opqrstuvcut.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://opqrstuvcut.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://opqrstuvcut.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://opqrstuvcut.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://opqrstuvcut.github.io/blog/categories/opencv/index.xml">
<link rel="alternate" hreflang="ja" href="https://opqrstuvcut.github.io/blog/categories/opencv/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  
    
      
    
  

<meta property="og:title" content="OpenCV" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://opqrstuvcut.github.io/blog/categories/opencv/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="OpenCV"/>
<meta name="twitter:description" content=""/>

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://opqrstuvcut.github.io/blog/" accesskey="h" title="MatLoverによるMatlab以外のブログ (Alt + H)">MatLoverによるMatlab以外のブログ</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://opqrstuvcut.github.io/blog/" title="Home">
                    <span>homeHome</span>
                </a>
            </li>
            <li>
                <a href="https://opqrstuvcut.github.io/blog/archives" title="Archives">
                    <span>archivesArchives</span>
                </a>
            </li>
            <li>
                <a href="https://opqrstuvcut.github.io/blog/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>searchSearch</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    OpenCV
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">画像の距離変換をおこなう
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
画像に対する距離変換とは、グレースケールの画像において、ピクセルから最も近い0の値をもつピクセルまでの距離を求めたものです。
早速OpenCVで試してみます。
OpenCVで距離変換 次のようにして距離変換をおこなえます。
dist = cv2.distanceTransform(img, distanceType=cv2.DIST_L2, maskSize=5 ) distanceTypeに距離の計算方法を指定します。DIST_L2はユークリッド距離です。 maskSizeには最も近い0の値をもつピクセルまでの距離の近似値を計算するときに使うmaskの大きさを指定します。maskSize=5の例でいえば、maskをあらわす$5\times5$の行列の各要素にはmaskの中心からの距離が格納されています。このmaskを使うことで、正確に距離を計算するよりも速く距離（の近似値）が計算できます。
結果は以下のとおりです。
入力画像 距離変換適用（明るいほど距離大） 背景が0の値をもつので、そこまでの距離が反映されています。窓の中心や、猫の顔の中心は背景から遠いので、大きな値をもっています。</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-07 11:00:00 +0900 JST'>8月 7, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 画像の距離変換をおこなう" href="https://opqrstuvcut.github.io/blog/posts/%E7%94%BB%E5%83%8F%E3%81%AE%E8%B7%9D%E9%9B%A2%E5%A4%89%E6%8F%9B%E3%82%92%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">floodFillで領域に色を塗る
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
OpenCVのfloodFillを使うことで、選んだ点の周辺の似たような色のピクセルを塗りつぶすことができます。
使い方 次のようにしてfloodFillを利用できます。
mask = np.zeros((img.shape[0] &#43; 2, img.shape[1] &#43; 2), dtype=np.uint8) res = cv2.floodFill(img, mask=mask, seedPoint=(400, 700), newVal=(0, 0, 255), loDiff=30, upDiff=30) まずmaskですが、入力画像の$(x,y)$がmaskの$(x&#43;1, y&#43;1)$に対応し、maskの値が0でないところは塗りつぶされません。入力画像に比べて縦横が2ピクセルずつ大きいので、元の画像の周辺に1ピクセルずつpaddingができたようなイメージですね。 seedPointに指定した座標が塗りつぶしの処理の起点になります。 newValに塗りつぶす色を指定します。 seedPointに指定したピクセルの値からloDiffを引いた値とseedPointに指定したピクセルの値にupDiffを加えた値の間に入っているピクセルをseedPointの隣から順に塗りつぶしていきます。
結果は以下のとおりです。
入力画像 floodFillの結果 </p>
  </div>
  <footer class="entry-footer"><span title='2020-08-06 11:08:00 +0900 JST'>8月 6, 2020</span></footer>
  <a class="entry-link" aria-label="post link to floodFillで領域に色を塗る" href="https://opqrstuvcut.github.io/blog/posts/floodfill%E3%81%A7%E9%A0%98%E5%9F%9F%E3%81%AB%E8%89%B2%E3%82%92%E5%A1%97%E3%82%8B/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Hough変換で円を検出
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
Hough変換は直線を検出する方法として前回紹介したのですが、Hough変換を応用することで、円の検出も行えます。
OpenCVで円の検出 次の画像から円を検出してみます。
円の検出は以下のようにおこないます。
hough_circle = cv2.HoughCircles(img, method=cv2.HOUGH_GRADIENT, dp=1, minDist=5, param1=100, param2=80) HoughLinesと異なり、画像はグレースケールの状態で渡せば、なかでエッジ検出をおこなってくれます。
methodには手法を指定しますが、HOUGH_GRADIENTしかないようです。
dpには分解能を指定しています。1にすると画像の解像度と同じ分解能をもちます。
minDistには円同士の最小の距離を指定します。これより近いと2つの円として認識されません。
param1はCanny法のしきい値の上限、param2は円上にあると判定されたエッジの点の数に対するしきい値です。
結果は以下のとおりです。
大まかには円が検出できていることがわかります。</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-05 11:05:00 +0900 JST'>8月 5, 2020</span></footer>
  <a class="entry-link" aria-label="post link to Hough変換で円を検出" href="https://opqrstuvcut.github.io/blog/posts/hough%E5%A4%89%E6%8F%9B%E3%81%A7%E5%86%86%E3%82%92%E6%A4%9C%E5%87%BA/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Non-Local Means Denoisingでノイズ除去
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
Non-Local Means Denoisingのアイデア 今回はノイズ除去を扱うのですが、特にガウスノイズを考えます。 これは平均が0となるノイズですので、着目しているピクセルにある意味で似ているピクセルを画像中から探してきて、それらの平均を取れば、ノイズの影響が消えたピクセルが得られるはずです。 これがNon-Local Means Denoisingのアイデアになります。
似ているピクセルをどう定義するか Non-Local Means Denoisingでは着目しているピクセルの値自体ではなく、着目しているピクセルの周辺の値同士の差分を取ることで、似ているかどうかを考えます。 この考えから定義されるピクセル$p$と$q$間の距離は以下のようになります。 $$ d^2(B(p, f), B(q,f)) = \frac{1}{3(2f &#43; 1)^2} \sum_{c=1}^3 \sum_{j \in B(0, f)} (I_c(p&#43;j) - I_c(q&#43;j))^2. $$ ここで$B(p,f)$は着目しているピクセル$p$のサイズの周辺のピクセルで、サイズが$(2f &#43; 1) \times (2f &#43; 1)$となっています。$I_c(p&#43;j)$が周辺ピクセルの$c$番目のchannelの値をあらわします。
平均値の取り方 先程定義した距離を使って以下のような重みを計算します。 $$ w(p,q) = e^{-\max(d^2 - 2\sigma^2, 0) / h^2}. $$ $\sigma^2$はノイズの分散になります（OpenCVの関数で実行するときには特にこれを指定しないので、上手く処理されている？）。$h$は与えるパラメーターで、大きいほど$w$の値に差がつきづらくなります。 距離$d^2$が小さいと$w$が1に近い値を取り、$d^2$が大きいほど$w$は小さい値になります。 この$w$を重みとしたピクセル値の重み付き平均を取ることがNon-Local Means Denoisingでの処理になります。
この重み付き平均をとることで、似ているピクセルは強く考慮されますが、似ていないピクセルはほとんど影響を与えないため、似ているピクセルだけでの平均が取れるような計算処理になっています。
なお、すべてのピクセル同士で距離$d^2$を計算すると、当然計算量が大変なことになります。 このため、実際には着目しているピクセルの周辺のどこまでを考慮するかを指定します。
OpenCVでやってみる OpenCVでNon-Local Means Denoisingをやってみます。
次の左の画像にノイズをのせて右の画像を生成しました。
これに対して次のようにして、Non-Local Means Denoisingを適用します。
denoised = cv2.fastNlMeansDenoisingColored(img, h=3, templateWindowSize=7, searchWindowSize=21) hはさきほどの重みで出てきた$h$と同じで、templateWindowSizeは$d^2$の計算で使われる$f$と同じで、searchWindowSizeは着目しているピクセルの周辺をどこまで考慮するかをあらわします。 ちなみに、fastNlMeansDenoisingという関数もありますが、カラー画像に対してはfastNlMeansDenoisingColoredが良いらしいです。...</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-01 10:04:00 +0900 JST'>8月 1, 2020</span></footer>
  <a class="entry-link" aria-label="post link to Non-Local Means Denoisingでノイズ除去" href="https://opqrstuvcut.github.io/blog/posts/non-local-means-denoising%E3%81%A7%E3%83%8E%E3%82%A4%E3%82%BA%E9%99%A4%E5%8E%BB/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">inpaintで画像の修復をする
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
画像に汚れがついたり、傷がついているケースの修復には、最近ではディープラーニングを使った手法が色々出ていますが、画像処理の範囲でもできることがあります。 今回はOpenCVで修復をおこなってみます。
OpenCVでやってみる 次の画像にノイズをのせていきます。
次のようなコードで画像にノイズをのせていきます。
cv2.rectangle(img, (100,100),(300,105),(255,255,255), -1) cv2.rectangle(img, (400, 450),(600,460),(255,255,255), -1) cv2.rectangle(img, (0, 750),(800, 760),(255,255,255), -1) plt.imshow(img[:, :, ::-1]) plt.show() mask = np.zeros(img.shape[:2], dtype=np.uint8) cv2.rectangle(mask, (100,100),(300, 105),(255), -1) cv2.rectangle(mask, (400, 450),(600,460),(255), -1) cv2.rectangle(mask, (0, 750),(800, 760),(255), -1) plt.imshow(mask) plt.gray() plt.show() ノイズがのった画像 ノイズ部分のmask画像 OpenCVのinpaint関数を使うと、このノイズがのった画像をある程度復元できます。 次のように利用します。
inpainted = cv2.inpaint(img, mask, 3, cv2.INPAINT_NS) 第一引数に復元したい画像を指定し、第二引数に復元したい箇所をあらわしたマスク画像を指定します。第三引数が復元時に周辺のピクセルをいくつ利用するかを指定します。第四引数に復元のアルゴリズムを指定します。INPAINT_NS（Navier Stokes法）かINPAINT_TELEA（Alexandru Telea法）を指定できます。
Navier Stokes法 Alexandru Telea法 どちらも結構いい感じに復元できています。右図のほうが文字の部分などはきれいに復元できている気がします。
ちなみにAlexandru Telea法で第三引数を10まで大きくしてみると、以下のようになります。
ちょっと復元した箇所が滲んだような感じになってしまってます。大きくしすぎには注意ですね。</p>
  </div>
  <footer class="entry-footer"><span title='2020-07-31 11:04:00 +0900 JST'>7月 31, 2020</span></footer>
  <a class="entry-link" aria-label="post link to inpaintで画像の修復をする" href="https://opqrstuvcut.github.io/blog/posts/inpaint%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E4%BF%AE%E5%BE%A9%E3%82%92%E3%81%99%E3%82%8B/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">透過変換で斜めから撮った画像を上から見下ろす
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
透過変換とは？ 透過変換はアフィン変換よりも柔軟な変換になっていまして、アフィン変換ではできない台形への変換が可能です。また台形から長方形への変換も可能です。 つまり、斜めに写っているものを上から見たような感じに変換ができるというわけです。
OpenCVでやってみる 次の画像を長方形の画像に変換することを考えます。
やりたいこととしてはこの本が斜めに（台形に）写っているので、これを長方形にすることです。
まず変換行列を作る必要があります。 これには次のようにgetPerspectiveTransformを使えば簡単にできます。
src = np.array([[830, 675], [26, 2872], [2579, 2852], [2350, 455]], dtype=np.float32) dst = np.array([[0, 0], [0, 1150], [800, 1150], [800, 0]], dtype=np.float32) perspective_mat = cv2.getPerspectiveTransform(src, dst) これはsrcで指定した4つの座標がdstで指定した4つの座標に変換されるような変換行列を作ってくださいと関数に依頼しています。 srcで指定している4点は本の4隅の座標です。dstの1150と800という数値は実際の本の縦横比から適当に決めました。
この行列を使い、次のように変換をおこないます。
transformed = cv2.warpPerspective(img, perspective_mat, (800, 1150)) plt.imshow(transformed[:, :, ::-1]) plt.show() それっぽく長方形になりました。 ちょっと文字などが斜めになっていますが、本の表紙が浮いているせいかもしれません。</p>
  </div>
  <footer class="entry-footer"><span title='2020-07-30 11:04:00 +0900 JST'>7月 30, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 透過変換で斜めから撮った画像を上から見下ろす" href="https://opqrstuvcut.github.io/blog/posts/%E9%80%8F%E9%81%8E%E5%A4%89%E6%8F%9B%E3%81%A7%E6%96%9C%E3%82%81%E3%81%8B%E3%82%89%E6%92%AE%E3%81%A3%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E4%B8%8A%E3%81%8B%E3%82%89%E8%A6%8B%E4%B8%8B%E3%82%8D%E3%81%99/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">画像へのアフィン変換
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
アフィン変換といえば、普通は2次元上の点や図形を拡大縮小したり、回転したり、平行移動したりといった変換をさします。 式の話をすると、ある2次元上の点$(x,y)$の$(x’, y’)$へのアフィン変換は次のようにして表現できます。 $$\begin{pmatrix}x’ \\ y’ \\ 1 \end{pmatrix} =\begin{pmatrix} a &amp; b &amp; c\\ e &amp; f &amp; g \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix}x \\ y \\ 1 \end{pmatrix}. $$ $a,b,e,f$の値によって拡大縮小、回転をおこなうようにできますし、$c,g$の値によって平行移動が可能です。
今回はこのアフィン変換をOpenCVを使っておこないます。
アフィン変換のやり方 OpenCVでは次のようにしてアフィン変換をおこないます。
transformed_img = cv2.warpAffine(img, affine_mat, (width, height)) affine_matとしているのが、アフィン変換で用いる行列です。 widthとheightは変換後の画像のサイズになります。
以下では次の画像に対するアフィン変換の例を示します。 平行移動 平行移動をするときは次のようなアフィン変換になります。 $$\begin{pmatrix}x’ \\ y’ \\ 1 \end{pmatrix} =\begin{pmatrix} 1 &amp; 0 &amp; c\\ 0 &amp; 1 &amp; g \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix}x \\ y \\ 1 \end{pmatrix}....</p>
  </div>
  <footer class="entry-footer"><span title='2020-07-29 11:03:00 +0900 JST'>7月 29, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 画像へのアフィン変換" href="https://opqrstuvcut.github.io/blog/posts/%E7%94%BB%E5%83%8F%E3%81%B8%E3%81%AE%E3%82%A2%E3%83%95%E3%82%A3%E3%83%B3%E5%A4%89%E6%8F%9B/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">動画の書き込み
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
OpenCVでの動画の書き込み方 次のようにしてtest.mp4という名前の動画を作成します。
fourcc = cv2.VideoWriter_fourcc(&#34;m&#34;, &#34;p&#34;, &#34;4&#34;, &#34;v&#34;) writer = cv2.VideoWriter(&#34;test.mp4&#34;, fourcc, 30, (1920, 1080)) print(writer.isOpened()) 第二引数のfourccは動画のコーデックをあらわしており、mp4のときにはcv2.VideoWriter_fourccの引数には&#34;m&#34;, “p”, “4”, “v&#34;を指定します。他にもmpgで保存するときには&#34;D”, “I”, “V”, “X&#34;を指定したりできます。拡張子に対応してどういうコーデックが指定できるかは、ググっていただくのが良いかと思います。 また、第三引数にFPSを第四引数に動画の横と縦の大きさを指定しています。 isOpenedメソッドにより動画を書き込むための準備ができているかを確認できます。FalseのときにはPCがコーデックに対応していなかったりで上手くいっていません。
実際に書き込みをおこなうときはwriteメソッドを使います。以下では3フレーム分書き込んでいます。
writer.write(frame) writer.write(frame) writer.write(frame) writer.release() # 書き込み後はreleaseする </p>
  </div>
  <footer class="entry-footer"><span title='2020-07-28 11:00:00 +0900 JST'>7月 28, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 動画の書き込み" href="https://opqrstuvcut.github.io/blog/posts/%E5%8B%95%E7%94%BB%E3%81%AE%E6%9B%B8%E3%81%8D%E8%BE%BC%E3%81%BF/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">動画の読みこみ
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
今日はOpenCVでの動画の読み書きを扱います。
動画の読み込み 動画の読み込みは簡単です。
最初に次のように保存されている動画を開きます。
import cv2 v = cv2.VideoCapture(&#34;./ex.mp4&#34;) カメラからフレームを取得する場合はデバイスのIDの指定すればよいです。 普通は次のように0を指定すればよいかと思います。
v = cv2.VideoCapture(0) フレームの読み込みは以下のようにします。
ret, frame = v.read() フレームが読み込めれば、retにはTrueが入ってきて、フレームが読み込めない状態になるとFalseが入ります。 これを利用すれば、次のようにしてフレームを次々に読み込めます（保存されているファイルを開いている場合には、動画の終わりまでが読み込まれます）。
while True: ret, frame = v.read() if not ret: break プロパティの取得 動画のフレームの大きさ、FPS、フレーム数は以下のようにして取得できます。
print(v.get(cv2.CAP_PROP_FRAME_WIDTH)) print(v.get(cv2.CAP_PROP_FRAME_HEIGHT)) print(v.get(cv2.CAP_PROP_FPS)) print(v.get(cv2.CAP_PROP_FRAME_COUNT)) 取得できるプロパティは以下に一覧があります。 http://opencv.jp/opencv-2svn/cpp/highgui_reading_and_writing_images_and_video.html</p>
  </div>
  <footer class="entry-footer"><span title='2020-07-27 22:53:54 +0900 JST'>7月 27, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 動画の読みこみ" href="https://opqrstuvcut.github.io/blog/posts/%E5%8B%95%E7%94%BB%E3%81%AE%E8%AA%AD%E3%81%BF%E3%81%93%E3%81%BF/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">sepFilter2Dで分離可能フィルタを使って高速化
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
OpenCVのfilter2Dを使うのは良いのですが、分離可能フィルタのときにはsepFilter2Dを使うことで、高速化できます。 今回はこのsepFilter2Dを扱います。
分離可能フィルタ 分離可能フィルタとは2つのベクトルの畳み込みであらわされるフィルタのことを指します。
分離可能フィルタの具体例1 Sobelフィルタは分離可能フィルタです。 X方向のSobelフィルタは以下であらわされます。
これは次のような2つのベクトルの畳み込みとしてあらわされます（$\ast$は畳み込みをあらわしています）。 $$ \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix} \ast	\begin{pmatrix} -1 &amp; 0 &amp; 1 \end{pmatrix}. $$
分離可能フィルタの具体例2 平滑化フィルタは分離可能フィルタです。 3×3のサイズの平滑化フィルタは次のような2つのベクトルの畳み込みとしてあらわされます。 $$ \begin{pmatrix} \frac{1}{3} \\ \frac{1}{3} \\ \frac{1}{3} \end{pmatrix} \ast	\begin{pmatrix} \frac{1}{3} &amp; \frac{1}{3} &amp; \frac{1}{3} \end{pmatrix}. $$
分離可能フィルタで高速化できる理由 行列形式のサイズ$n$のカーネルを使う場合には1回の畳み込み演算に$n^2$のオーダーの計算量が必要です（実際、掛け算は$n^2$回、足し算は$n^2-1$回です）。これを画像のピクセルの数$S$だけおこなうとすると、$n^2S$のオーダーの計算量がかかります。
次に分離した2つのベクトルであらわされたカーネルを2回適用するケースを考えます。このカーネルの1回の畳み込みには$n$のオーダーの計算量がかかります。これをすべてのピクセルに2回適用すると、計算量のオーダーは$2nS$です。
以上から$n$が大きくなると、計算量に大きな違いがでることがわかります。
実際にsepFilter2Dを試す sepFilter2Dは以下のようにして利用できます。
sep_filter_res = cv2.sepFilter2D(img, ddepth=cv2.CV_16S, kernelY=col_kernel, kernelX=row_kernel) kernelXに行ベクトルのカーネルを指定し、kernelYに列ベクトルのカーネルを指定しています。
実際にSobelフィルタを適用することを考えます。
col_kernel = np.array([1, 2, 1]).T row_kernel = np.array([-1, 0, 1]) sep_filter_res = cv2....</p>
  </div>
  <footer class="entry-footer"><span title='2020-07-26 11:06:00 +0900 JST'>7月 26, 2020</span></footer>
  <a class="entry-link" aria-label="post link to sepFilter2Dで分離可能フィルタを使って高速化" href="https://opqrstuvcut.github.io/blog/posts/sepfilter2d%E3%81%A7%E5%88%86%E9%9B%A2%E5%8F%AF%E8%83%BD%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E9%AB%98%E9%80%9F%E5%8C%96/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="https://opqrstuvcut.github.io/blog/categories/opencv/">
      «&nbsp;前へ&nbsp;
    </a>
    <a class="next" href="https://opqrstuvcut.github.io/blog/categories/opencv/page/3/">次へ&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://opqrstuvcut.github.io/blog/">MatLoverによるMatlab以外のブログ</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
