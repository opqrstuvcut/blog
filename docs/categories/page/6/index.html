<!DOCTYPE html>
<html lang="ja-jp"
  x-data
  :class="$store.darkMode.class()"
  :data-theme="$store.darkMode.theme()">
  <head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=50000&amp;path=blog/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>


カテゴリー一覧 | MatLoverによるMatlab以外のブログ</title>

    
<link href="/blog/favicon.ico" rel="shortcut icon" type="image/x-icon" />


<link rel="canonical" href="http://localhost:50000/blog/categories/" />



<meta name="author" content="" />
<meta name="description" content="" />



<meta name="generator" content="Hugo 0.133.0">


<meta property="og:url" content="http://localhost:50000/blog/categories/">
  <meta property="og:site_name" content="MatLoverによるMatlab以外のブログ">
  <meta property="og:title" content="Categories">
  <meta property="og:locale" content="ja_jp">
  <meta property="og:type" content="website">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Categories">


<link rel="stylesheet" href="/blog/css/output.css" />




     

    

    <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js"></script>
  </head>

  <body x-data="{
    flip: false,
  }">
    
    <div id="dream-global-bg"></div>

    
<nav class="mt-4 lg:mt-8 py-4">

  
  <div class="container flex justify-between px-4">
  
    <section class="flex items-center gap-4">
      <div class="avatar cursor-pointer hover:online" @click="flip = !flip" title="Flip it!">
        <div class="h-10 rounded-full">
          <img src="/blog/" alt="" />
        </div>
      </div>

      
    </section>

    <div class="dropdown dropdown-end sm:hidden">
      <div tabindex="0" role="button" class="btn btn-ghost btn-square" aria-label="Select an option">
        <ion-icon name="menu" class="text-2xl"></ion-icon>
      </div>
      <ul class="dropdown-content menu w-36 bg-base-100 rounded-box z-[1] shadow-md">
        


























<li>
  <a class="inline-flex items-center p-2 cursor-pointer" href="/blog/categories" title="カテゴリー一覧">
    <ion-icon name="grid"></ion-icon>
    カテゴリー一覧
  </a>
</li>




<li>
  <a class="inline-flex items-center p-2 cursor-pointer" href="/blog/tags" title="タグ一覧">
    <ion-icon name="pricetags"></ion-icon>
    タグ一覧
  </a>
</li>






      </ul>
    </div>
    <section class="hidden sm:flex sm:items-center sm:gap-2 md:gap-4">
      

      
      

      

      
      





      
      





      
      





      
      
<a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="/blog/categories" title="カテゴリー一覧">
  <ion-icon class="group-hover:text-primary-content" name="grid"></ion-icon>
</a>


      
      
<a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href="/blog/tags" title="タグ一覧">
  <ion-icon class="group-hover:text-primary-content" name="pricetags"></ion-icon>
</a>


      

      

      
    </section>
  </div>
</nav>


    <div class="flip-container" :class="{ 'flip-it': flip }">
      <div class="flipper">
        <div class="front">
          <div class="container">
            


<div class="flex flex-col md:flex-row mt-4">

  <div class="md:basis-[200px] lg:basis-[300px] p-4 prose dark:prose-invert">
    <h1 class="text-2xl">カテゴリー一覧</h1>
    <p class="text-sm">27カテゴリー</p>
    <div class="flex flex-wrap gap-4 mt-6">
      
      <a href="/blog/categories/app-runner/" class="badge h-6 no-underline hover:badge-primary">
        App Runner
      </a>
      
      <a href="/blog/categories/aws/" class="badge h-6 no-underline hover:badge-primary">
        AWS
      </a>
      
      <a href="/blog/categories/chrome/" class="badge h-6 no-underline hover:badge-primary">
        Chrome
      </a>
      
      <a href="/blog/categories/deep-learning/" class="badge h-6 no-underline hover:badge-primary">
        Deep Learning
      </a>
      
      <a href="/blog/categories/docker/" class="badge h-6 no-underline hover:badge-primary">
        Docker
      </a>
      
      <a href="/blog/categories/ecs/" class="badge h-6 no-underline hover:badge-primary">
        ECS
      </a>
      
      <a href="/blog/categories/feature-importance/" class="badge h-6 no-underline hover:badge-primary">
        Feature Importance
      </a>
      
      <a href="/blog/categories/flutter/" class="badge h-6 no-underline hover:badge-primary">
        Flutter
      </a>
      
      <a href="/blog/categories/gcp/" class="badge h-6 no-underline hover:badge-primary">
        GCP
      </a>
      
      <a href="/blog/categories/gpu/" class="badge h-6 no-underline hover:badge-primary">
        GPU
      </a>
      
      <a href="/blog/categories/kubernetes/" class="badge h-6 no-underline hover:badge-primary">
        Kubernetes
      </a>
      
      <a href="/blog/categories/opencv/" class="badge h-6 no-underline hover:badge-primary">
        OpenCV
      </a>
      
      <a href="/blog/categories/opencv%E7%94%9F%E6%B4%BB/" class="badge h-6 no-underline hover:badge-primary">
        OpenCV生活
      </a>
      
      <a href="/blog/categories/pandas/" class="badge h-6 no-underline hover:badge-primary">
        Pandas
      </a>
      
      <a href="/blog/categories/python/" class="badge h-6 no-underline hover:badge-primary">
        Python
      </a>
      
      <a href="/blog/categories/sql/" class="badge h-6 no-underline hover:badge-primary">
        SQL
      </a>
      
      <a href="/blog/categories/tensorflow/" class="badge h-6 no-underline hover:badge-primary">
        TensorFlow
      </a>
      
      <a href="/blog/categories/uwsgi/" class="badge h-6 no-underline hover:badge-primary">
        UWSGI
      </a>
      
      <a href="/blog/categories/vim/" class="badge h-6 no-underline hover:badge-primary">
        Vim
      </a>
      
      <a href="/blog/categories/vim%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3/" class="badge h-6 no-underline hover:badge-primary">
        Vimプラグイン
      </a>
      
      <a href="/blog/categories/%E7%94%BB%E5%83%8F%E5%87%A6%E7%90%86/" class="badge h-6 no-underline hover:badge-primary">
        画像処理
      </a>
      
      <a href="/blog/categories/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/" class="badge h-6 no-underline hover:badge-primary">
        機械学習
      </a>
      
      <a href="/blog/categories/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86/" class="badge h-6 no-underline hover:badge-primary">
        自然言語処理
      </a>
      
      <a href="/blog/categories/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/" class="badge h-6 no-underline hover:badge-primary">
        深層学習
      </a>
      
      <a href="/blog/categories/%E6%95%B0%E5%AD%A6/" class="badge h-6 no-underline hover:badge-primary">
        数学
      </a>
      
      <a href="/blog/categories/%E6%95%B0%E5%80%A4%E8%A8%88%E7%AE%97/" class="badge h-6 no-underline hover:badge-primary">
        数値計算
      </a>
      
      <a href="/blog/categories/%E7%B5%B1%E8%A8%88/" class="badge h-6 no-underline hover:badge-primary">
        統計
      </a>
      
    </div>
  </div>
  
  <div class="divider divider-vertical md:divider-horizontal px-4 md:px-0"></div>
  
  <div class="flex-1">
    

    
    <div class="dream-grid">
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/laplacian%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE2%E9%9A%8E%E5%BE%AE%E5%88%86/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default2_hu4245215999118357849.webp" type="image/webp" />
      <img src="/blog/images/default2.jpg" alt="/images/default2.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">Laplacianで画像の2階微分</h2>

    <p class="date text-base-content/60">
    
      土曜日, 7月 18, 2020
    
    </p>

    本記事はQrunchからの転載です。
今回はLaplacianを扱います。
そもそものLaplacian Laplacianの復習的な話ですが、2階偏微分可能な関数$f(x,y)$に対して以下をLaplacianといいます。 $$ \Delta f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}. $$
これを画像に適用することで、ピクセル値の極小値あるいは極大値となるピクセルを見つけることが可能になります。これはエッジ検出に利用可能だということがわかるかと思います。
Laplacianのフィルタ Laplacianのフィルタの最も基本的なものは以下で定義されます。
これを使った畳み込み演算によってLaplacianができるという主張ですが、このフィルタの導出は以下のとおりです。
$(x,y)$の位置にあるピクセルの1階の偏微分の近似は以下のようにあらわされます。
$$ \frac{\partial f}{\partial x} \approx f(x + 1, y) - f(x,y ).$$ これを利用すると、2階の偏微分は
$$\begin{aligned} \frac{\partial^2 f}{\partial x^2} &amp;\approx&amp; f(x+1,y ) - f(x, y) - (f(x,y ) - f(x-1,y )) \\ &amp;=&amp; f(x+1, y) - 2f(x, y) + f(x-1,y ).\end{aligned}$$ 同様に $$ \begin{aligned} \frac{\partial^2 f}{\partial y^2} &amp;\approx&amp; f(x,y+1) - f(x, y) - (f(x,y ) - f(x,y-1 )) \\ &amp;=&amp; f(x, y+1) - 2f(x, y) + f(x,y-1 ).

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/sobel%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%A7%E5%BE%AE%E5%88%86/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default1_hu18298318514717008910.webp" type="image/webp" />
      <img src="/blog/images/default1.jpg" alt="/images/default1.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">Sobelフィルタで微分</h2>

    <p class="date text-base-content/60">
    
      木曜日, 7月 16, 2020
    
    </p>

    本記事はQrunchからの転載です。
よくある画像処理のオペレーターとして、画像の微分があります。 いくつかやり方はありますが、今日はSobel微分を取り上げます。
Sobelフィルタ Sobel微分はSobelフィルタを使った畳み込みをすることで実現できます。 例えば、3×3のSobelフィルタは以下のようなカーネルになります。
x方向の微分用のSobelフィルタ
y方向の微分用のSobelフィルタ
これらのフィルタは何をあらわしているんでしょうか？ 実はSobelフィルタは微分と平滑化をあわせもったフィルタになっています。 ここでいう微分のフィルタとはx方向の場合には以下を指します。
これは$(x,y)$座標のピクセルに注目しているときに、その左右にあるピクセルの差を取る演算を示しています。いわゆる中心差分と呼ばれる微分の計算方法になります。
次に平滑化ですが、これは以下のフィルタです。
ガウス平滑化に似たように中心の重みが大きい平滑化になります。
ここまでで定義した微分のフィルタに対して平滑化のフィルタによる畳込みを計算すると、実はSobelフィルタと同じものがあらわれます。つまり、画像に対して微分のフィルタを適用した後に平滑化のフィルタを適用することとと、画像に対してSobelフィルタを適用することは等しいです。
以上がSobelフィルタが何をしているかの話になります。
Sobelフィルタを適用 OpenCVでは以下のようにすることで、Sobelフィルタを適用できます。
soblex = cv2.Sobel(img, ddepth=cv2.CV_16S, dx=1, dy=0, ksize=3) 第二引数のddepthにSobelによる返り値を格納する型を指定します。CV_16Sは符号付きの16ビット整数です。 第三、第四引数のところは微分する次数を指定します。dx=1、dy=0とすると、x方向のSobelフィルタを使うことになりますし、dx=0、dy=1とするとy方向のSobelフィルタです。 最後のksizeはカーネルサイズになります。一応31まで指定が可能なようです。
次の画像にSobelフィルタを適用してみます。
x方向のSobelフィルタの適用
soblex = cv2.Sobel(noise_img, ddepth=cv2.CV_16S, dx=1, dy=0, ksize=3, ) 正の勾配は白色、負の勾配は黒色で描画されています。
y方向のSobelフィルタの適用
sobley = cv2.Sobel(noise_img, ddepth=cv2.CV_16S, dx=0, dy=1, ksize=3, ) これも同様に正の勾配は白色、負の勾配は黒色で描画されています。
なお、それぞれのSobelフィルタの適用結果を足し合わせると次のようになります。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/imencode%E3%81%A8imdecode%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A1%E3%83%A2%E3%83%AA%E4%B8%8A%E3%81%A7%E3%81%AE%E7%94%BB%E5%83%8F%E5%9C%A7%E7%B8%AE/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default1_hu18298318514717008910.webp" type="image/webp" />
      <img src="/blog/images/default1.jpg" alt="/images/default1.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">imencodeとimdecodeによるメモリ上での画像圧縮</h2>

    <p class="date text-base-content/60">
    
      木曜日, 7月 16, 2020
    
    </p>

    本記事はQrunchからの転載です。
画像をpngなどからjpgに変換したいときに、ぱっと思いつくのはファイルを読み込んで、それをjpgの拡張子で書き込みした後に再度読み込みなおすことです。 1度動かすならばそれでも良いのですが、何度も繰り返しおこなう場合にはファイルの読み書きの時間が気になります。
OpenCVではファイルへの読み書きをおこなうことなく、メモリ上でファイル形式を変更できる（jpgへの圧縮などができる）ような方法が提供されています。
流れとしては、imencodeでメモリ上にファイル形式を変更したバイト列を作成し、それをimdecodeで画像に変換するという流れになります。imencodeがファイルへの書き込み、imdecodeがファイルの読み込みに対応する感じになります。
imencode 画像を他のファイルを形式に変更するimencodeは次のようにして利用します。
ret, encoded = cv2.imencode(&#34;.jpg&#34;, img, (cv2.IMWRITE_JPEG_QUALITY, 10)) 1つめの引数がどの拡張子に変換するかをあらわす文字列で、ここではjpgを指定しています。
3つめの引数に指定した拡張子に変換するときのパラメータを指定します。 例えばjpgの場合には画像の質を指定できますので、それをタプルの形式で与えており、ここではjpgの質を10で圧縮するようにしています。
imencodeによって生成されたjpgになった画像の情報はencodedに格納されています。
imdecode メモリ上の画像データを読み込むimdecodeは以下のようにします。
decoded = cv2.imdecode(encoded, flags=cv2.IMREAD_COLOR) 第一引数はimencodeの出力です。 flagsは何かしら指定しないといけないのですが、これはどう読み込むかをあらわすフラグです。 BGRの3channelで読み込む場合にはcv2.IMREAD_COLORを指定し、Gray scaleの1channelで読み込む場合にはcv2.IMREAD_GRAYSCALEを指定します。
適用結果 jpgのqualityを10にしてimencodeした後にimdecodeした結果を元の画像と比較してみます。
元画像 imdecode後の画像 右側の画像はノイズがのっていることが分かるでしょうか？ちゃんとjpgの形式で圧縮されたようです。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/%E3%82%B5%E3%83%B3%E3%83%97%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89%E3%81%A7%E3%81%AA%E3%81%AB%E3%81%8B%E3%81%A8%E3%81%82%E3%82%89%E3%82%8F%E3%82%8C%E3%82%8B%E3%82%AC%E3%82%A6%E3%82%B9%E5%B9%B3%E6%BB%91%E5%8C%96/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default2_hu4245215999118357849.webp" type="image/webp" />
      <img src="/blog/images/default2.jpg" alt="/images/default2.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">サンプルコードでなにかとあらわれるガウス平滑化</h2>

    <p class="date text-base-content/60">
    
      火曜日, 7月 14, 2020
    
    </p>

    本記事はQrunchからの転載です。
今日はなにかとサンプルコードで使われるガウス平滑化です。
ガウス平滑化とは 前々回取り上げた単純平滑化は局所領域の平均をとることで、平滑化をおこないました。これは局所領域内の各ピクセルの重み付けがすべて等しいともいえます。 ガウス平滑化では二次元のガウス分布を離散化した値を重みとして利用するような平滑化になります。 $$g(x,y) = \frac{1}{2\pi\sqrt{\sigma^2}}\exp\left(-\frac{x^2 + y^2}{\sigma^2}\right).$$
単純平滑化との違いは？ 具体的なカーネルの比較の例は以下のとおりです。
単純平滑化 ガウス平滑化 ガウス平滑化の場合には中心の重みが大きく、そこから遠ざかるほど、重みが小さくなっていきます。
画像に与える影響の違いとしては、単純平滑化よりも中心の重みが大きいことで、平滑化後のボケが少ないことが挙げられます。
単純平滑化とガウス平滑化の違いを実験 OpenCVでガウス平滑化を使う場合は以下のようにすればOKです。
blur = cv2.GaussianBlur(img, ksize=(9, 9), sigmaX=2, sigmaY=2) ksizeはカーネルの大きさ（局所領域のサイズ）、sigmaXはガウス分布のx方向の分散、sigmaYはy方向の分散になります。分散は0を入れると、デフォルト値を計算し、それを利用してくれます。
次のようなノイズを乗せた画像を用意しました。
それぞれの平滑化の適用結果が以下のとおりです。すべてカーネルサイズは9×9です。
単純平滑化 メディアンフィルタ ガウス平滑化 単純平滑化とガウス平滑化を比べると、ガウス平滑化のほうが若干ノイズが多めの気がしますが、ボケが少ないです。 メディアンフィルタはノイズは取れますが、もとの情報が結構落ちてますね。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/%E5%A4%96%E3%82%8C%E5%80%A4%E3%81%AB%E5%BC%B7%E3%81%84medianblur/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default4_hu11774824972063855820.webp" type="image/webp" />
      <img src="/blog/images/default4.jpg" alt="/images/default4.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">外れ値に強いMedianBlur</h2>

    <p class="date text-base-content/60">
    
      月曜日, 7月 13, 2020
    
    </p>

    本記事はQrunchからの転載です。
単純平滑化の場合には、局所領域内での平均を取るため、周辺とは大きく異なるピクセル値をもつピクセルがあると、その影響が大きすぎて上手くいかない場合があります。 そのようなケースでは中央値を使うようにすると、上手くいくかもしれません。
medianBlur OpenCVではmedianBlurという関数で局所領域内の中央値を使うような平滑化をおこなえます。
以下がmedianBlurを実際に実行したコードになります。
import cv2 import matplotlib.pyplot as plt image = cv2.imread(&#39;noro-min.jpeg&#39;) blur = cv2.medianBlur(img, ksize=5) blur = cv2.cvtColor(blur, cv2.COLOR_BGR2RGB) plt.imshow(blur[:, :, ::-1]) plt.show() 人工的に画像にノイズを乗せて、blurとmedianBlurを適用した結果を比べてみます。
ノイズを乗せた画像 blurを適用した画像 medianBlurを適用した画像 中央値を使うことで、ノイズを上手く取り除くことができています。 ただし、文字の部分などは結構ボケるようになりました。中央値を使うと、白い背景と近い部分のピクセルはすべて白に置き換えられてしまうからです。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/adaptivethreshold%E3%81%A7%E7%85%A7%E6%98%8E%E7%92%B0%E5%A2%83%E3%81%8C%E5%BE%AE%E5%A6%99%E3%81%AA%E7%94%BB%E5%83%8F%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default3_hu11811107914568380876.webp" type="image/webp" />
      <img src="/blog/images/default3.jpg" alt="/images/default3.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">AdaptiveThresholdで照明環境が微妙な画像を二値化</h2>

    <p class="date text-base-content/60">
    
      土曜日, 7月 11, 2020
    
    </p>

    本記事はQrunchからの転載です。
画像処理で結構シビアなのが、照明環境です。 例えば次の画像のように、画像の中で明暗が異なると、大津の二値化ではうまくいきません。
入力画像 大津の二値化適用 とはいえ、アプリケーションによっては撮影者に常に気をつけてもらうことも難しかったりします。 そんなときにはAdaptiveThresholdが役に立ちます。
AdaptiveThresholdとは？ OpenCVで使えるAdaptiveThresholdには2パターンあるのですが、まずは簡単な局所領域での平均を利用する方から説明します。
局所領域での平均を用いたAdaptiveThreshold この方法では、ある座標$(x,y)$のピクセルの二値化をおこなうときには、$(x,y)$を中心としたある大きさの局所領域内の各ピクセルのグレースケール値の平均値を計算します。 この平均値から指定した定数を引いた値をしきい値$T(x,y)$とします。 もし$(x,y)$のグレースケール値が$T(x,y)$を超えれば255に置き換え（255以外にもこの値は指定できます）て、$T(x,y)$以下であれば、$0$にします。
ざっくり言えば、$(x,y)$の周辺領域の平均値を二値化のしきい値にするということになります。
こうすると何が良いかといえば、周辺領域が暗ければ、しきい値は暗い方に設定されますし、周辺領域が明るければ、しきい値は明るい方に設定されます。つまり、局所領域内である程度明暗がわかれていれば、きちんと二値化ができるということです。すごいですね。
この方法は、次のようにcv2.adaptiveThresholdによって利用可能です。
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) bi_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 5) plt.imshow(bi_img) plt.gray() plt.show() ちゃんとそれっぽく二値化されてます！
adaptiveThresholdの各引数は以下のとおりです。 局所領域は$(x,y)$を中心とした領域になるため、領域の大きさは奇数で指定しなければいけないことに注意してください。
引数 意味 1 入力画像 2 ここで説明した方法を使うことをあらわす値 3 threshold typeでこれは前々回説明したものと同じ 4 周辺領域の大きさで、11ということは11×11の領域で平均値を計算している 5 しきい値を決めるときに平均値から引かれる定数 局所領域でのガウス分布による重み付を用いたAdaptiveThreshold 先程の平均値は局所領域内は平等に扱うような方法でしたが、問題によっては、局所領域の中心$(x,y)$に近いほど重要視して、遠ざかるほど影響を小さくしたいなぁと思うときがあります。 そんなときにはガウス分布による重み付けを利用することができます。
OpenCVで利用するときにはさきほどの第二引数をcv2.ADAPTIVE_THRESH_GAUSSIAN_Cに変えるだけでOKです。
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) bi_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 5) plt.imshow(bi_img) plt.gray() plt.show() こちらも上手くいっています。
おわりに 問題設定によっては平均の方だと上手くいかず、ガウス分布の重み付けのほうは上手くいったりしますので、そのあたりの使い分けは試行錯誤するしかないかなと思います。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/%E5%A4%A7%E6%B4%A5%E3%81%AE%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%A7%E6%A5%BD%E3%82%92%E3%81%99%E3%82%8B/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default4_hu11774824972063855820.webp" type="image/webp" />
      <img src="/blog/images/default4.jpg" alt="/images/default4.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">大津の二値化で楽をする</h2>

    <p class="date text-base-content/60">
    
      金曜日, 7月 10, 2020
    
    </p>

    本記事はQrunchからの転載です。
大津の2値化とは？ シンプルな二値化では、何かしらのしきい値を決めてあげる必要がありました。
人間がグレースケール値のヒストグラムを見てしきい値を決めたり、試行錯誤するというのも良いですが、場合によってはしきい値を自動で決定したくなります。
そのような方法として有名なのが大津の2値化です。 大津の2値化を使うことで、ある意味での最適なしきい値を決定してくれます。
大津の2値化の中身は？ 大津の2値化では、グレースケールのヒストグラムを描いたときに、山が2つ存在するケースを想定しています。例えば次のようなヒストグラムです。
つまり、画像の白い部分と黒い部分の区別がある程度はっきりとつくようなケースを指しています。 白いところ、黒いところ、それらの間くらいの色の3種類が多数を占めているような、ヒストグラム上で山が3つできるような状況は想定されていません（アプリケーションによっては、それでも上手くいくかもしれませんが）。
さて、ヒストグラムが2つの山をもつようなグレースケールの画像が与えられたとして、大津の2値化はどのようにしきい値を決めているのでしょうか？
大津の2値化では、しきい値以下のグレースケール値としきい値より大きい値のグレースケール値の2つのグループにわけ、それぞれの分散をそれぞれ計算した後、それらの重み付きの和を考えます。しきい値はこの分散の重み付き和が最小になるように決められます。
式であらわせば、グレースケール値のしきい値$t$、しきい値$t$以下のグループの分散$\sigma-2_1(t)$、しきい値より大きいグループの分散$\sigma^2_2(t)$、しきい値以下の値の個数$q_1(t)$、しきい値より大きい値の個数$q_2(t)$を用いて以下のようになります。
$$ \sigma^2(t)=p_1(t) \sigma^2_1(t) + p_2(t) \sigma^2_2(t).$$
大津の2値化では$\sigma^2(t)$を最小化するようなしきい値$t$を見つけます。
直感的には分散が最小になるようなしきい値を見つけるのは良い方法のように思えます。 なぜかといえば、谷の部分からしきい値を動かしていき、どちらかの山の一部が他方のグループに取り込まれると、取り込まれた分が与える分散の増加分が非常に大きいと予想できるからです。
大津の2値化の適用結果 大津の2値化を実際に適用してみます。 次のようなグレースケールの画像が与えられたとします。
この画像のグレースケール値のヒストグラムは以下のとおりです（先程のヒストグラムと同じものです）。
大津の2値化を適用する際にはThreshoold typeのところにcv2.THRESH_OTSUを追加します。
ret, bin_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) 上記のようなコードを実行すると、大津の2値化によって2値化された画像が得られます。
img = cv2.imread(&#34;ex_img.jpg&#34;) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, bin_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) plt.imshow(bin_img) plt.gray() plt.show() しきい値が自動で適切に設定され、キレイに二値化できてますね。
ガウシアンフィルタとの組み合わせ ここでは詳しくは述べませんが、ノイズが多い画像では、ガウシアンフィルタで平滑化することでノイズが軽減され、ヒストグラムの山がよりシャープになりえます。
そうすると、大津の2値化後の結果がより人間の感覚にあったものとなったりします。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/%E8%B2%A7%E4%B9%8F%E4%BA%BA%E3%81%AA%E3%81%AE%E3%81%A7poor-mans-bert%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A7%E8%A7%A3%E8%AA%AC/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default1_hu18298318514717008910.webp" type="image/webp" />
      <img src="/blog/images/default1.jpg" alt="/images/default1.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">貧乏人なのでPoor Man’s BERTを読んで解説</h2>

    <p class="date text-base-content/60">
    
      日曜日, 6月 21, 2020
    
    </p>

    本記事はQrunchからの転載です。
最近自然言語処理をよくやっていて、BERTを使うことも多いです。 BERTの性能は高く素晴らしいのですが、実際使う上では、私のような計算リソース弱者には辛いところがあります。
例えば、BERTは非常にパラメータ数が多いことで有名ですが、パラメータが多いと、fine-tuningでの学習や推論の時間がかかることや大きめのメモリが積んであるGPUがないと学習ができない、といった部分がネックになりえます。
BERTのパラメータ数を減らす試みとしてはTinyBERTやDistilBERTによる蒸留を使った手法がありますが、今回紹介するPoor Man’s BERT: Smaller and Faster Transformer ModelsではBERTのTransformerの数を単純に減らすことでパラメータ数を減らしています。
実際にTinyBERTやDistilBERTと同じことをするのは難しいですが、今回のように層を減らして学習するのは容易にできますので、とても実用性があるのではないかと思います。
比較実験 論文では12層のTransformerをもつBERTモデルから色々な方法でTransformerを減らし、性能比較をおこなっています。24層をもつ、いわゆるBERT-Largeは、貧乏人にはメモリが足らずにfine-tuningも難しいのです。
次の図がTransformer層の減らし方の一覧です。
各方法の詳細は以下のとおりです。
Top-Layer Dropping 先行研究によると、BERTの後ろの層は目的関数に特化したような重みになっているようです。つまり、BERTで汎用的に使えるように学習されている部分は前の層ということになります。 このため、後ろの層に関しては減らしても性能がそんなに悪化しないんじゃないかという仮定のもと、BERTの最後から4つあるいは6つのTransformerを削除します。
Even Alternate Dropping、Odd Alternate Dropping 先行研究によると、BERTの各層では冗長性があります。つまり、隣り合った層の出力は似ているということです。 このため、1個おきにTransformerを削除します。
Contribution based Dropping Alternate Droppingと少し似ていますが、入力と出力があまり変わらないような層を削除するような方法です。 各Transformer層のなかで[CLS]の入力と出力のcosine類似度が大きい傾向にある層をあらかじめ見つけておき、それを削除します。
Symmetric Dropping もしかすると、12層のTransformerのうち、真ん中のあたりはあまり重要じゃないかもしれません。 ということで、前と後ろは残して真ん中付近のTransformerを削除します。
Bottom-Layer Dropping BERTの最初のほうの層が文脈の理解に重要といわれており、最初のほうを消す理論的な理由はないですが、年のために最初のほうのTransformerを削除したモデルも試します。
実験 手法間の性能比較 先程示した方法とDistilBERTをGLUEタスクのスコアで比較した結果が以下になります。BERTだけではなくXLNetでも実験してくれています。
これから以下のことが分かります。
各方法のスコアは12層あるBertには劣る。 4層減らす分にはBottom-Layer Dropping以外の方法ではそれほど性能に差がでないが、6層減らす場合にはTop-Layer Dropping（最後の6層を消す）が性能劣化が小さい。 Top-Layer Droppingの6層を消した場合はDistilBERTと似たような性能になっている。学習の手間はDistilBERTのほうが圧倒的に大きいので、性能が同程度、計算時間も同程度ならば本手法を使うメリットが大きいです。 XLNetの場合には最後の4層を消したモデルでも12層あるXLNetとほぼ同じ性能が出せる（＝性能劣化が少ない）。 タスクごとの性能変化の検証 次にタスクごとの性能の変化を見ていきます。前の実験から後ろの層を消していくTop-Layer Droppingが良いとわかっているため、Top-Layer Droppingに限って実験がされています。
問題によっては6層消してもほとんど変化がなかったりします。
余談ですが、私が自分で試したある問題では6層消して8ポイント分、4層消して4ポイント分の性能劣化、2層消して2ポイント分の性能劣化になりました。
タスクごとの性能劣化がおこる層数の検証 タスクごとに後ろを何層削ると1%、2%、3%の性能劣化がおこるのかを示した表です。
ビックリしますが、XLNetは結構層を消しても性能劣化が起こりづらいですね。
パラメータ数や計算時間比較 学習時間・推論時間は削った層の割合だけおおよそ減ることが予想されますが、実際に計算時間がどれくらい変わったかを示したのが以下の表です。
6層削ったモデルでは学習時間・推論時間の両方でだいたい半分くらいになってますね。
BERTとXLNetの層数での比較 BERTとXLNetのTransformerの数を変えると、どう性能が変化するかを示したのが以下の図です。
なんとXLNetは7層にするあたりまではほどんど性能の変化がありません。BERTは層を減らすと順調に性能が悪化します。
上記の話には実験的な根拠があり、それを示したのが以下の図です。
これはBERTとXLNetの事前学習モデルとfine-tunedモデル間で同じ層同士の出力のcosine類似度を計算した結果になります。つまり、小さい値になっているほど、fine-tuningで出力が大きく変わるような学習がおこなわれたことになります。 BERTの場合には後ろの層ほど大きな変化があることがわかります。またfine-tuningしても前の方の層はほとんど変わっていませんね。 一方でXLNetの場合には前の層の変化がないのはBERTと一緒ですが、後ろの層に関してもあまり変化がありません（もちろん12層目だけは大きく変わります）。つまり、問題を解くときにあまり8層以降は重要じゃないのではと考えられます。

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/aws%E3%81%AElambda%E3%81%8B%E3%82%89postgres%E3%82%92%E5%88%A9%E7%94%A8/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default2_hu4245215999118357849.webp" type="image/webp" />
      <img src="/blog/images/default2.jpg" alt="/images/default2.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">AWSのLambdaからPostgresを利用</h2>

    <p class="date text-base-content/60">
    
      月曜日, 5月 4, 2020
    
    </p>

    本記事はQrunchからの転載です。
AWSのLambda（Python）からPostgresを利用するためのライブラリの使い方のメモです。何もトラブルなく使えましたが、一応。 ライブラリのレポジトリはこちらです。
ライブラリのclone git clone https://github.com/jkehler/awslambda-psycopg2.git 適切な名前にリネーム LambdaでPython3.6を利用する場合にはcloneしてきたレポジトリにあるpsycopg2-3.6をpsycopg2にリネームします。あるいはPython3.7を利用する方はpsycopg2-3.7をpsycopg2にリネームします。
適切な位置への配置
psycopg2をLambdaにデプロイするコードと同じディレクトリに配置します。 例： lambda/hoge.pyというPythonスクリプトをデプロイする場合にはlambdaディレクトリ以下にpsycopg2を配置する。
Lambdaにデプロイする！

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>1分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
      <div class="w-full md:w-1/2 lg:w-1/3 p-4 dream-column">
        <a class="card card-compact bg-base-100 hover:bg-base-content/10 shadow-xl cursor-pointer dark:border dark:border-base-content/30" href="/blog/posts/%E9%96%A2%E6%95%B0%E3%81%8C%E4%B8%8A%E3%81%AB%E5%87%B8%E3%81%A7%E3%81%82%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AE%E5%BF%85%E8%A6%81%E5%8D%81%E5%88%86%E6%9D%A1%E4%BB%B6%E3%81%AF%E3%83%98%E3%83%83%E3%82%BB%E8%A1%8C%E5%88%97%E3%81%8C%E5%8D%8A%E8%B2%A0%E5%AE%9A%E5%80%A4%E3%81%AE%E8%A8%BC%E6%98%8E/">
  
  <figure>
    
    
    <picture>
      <source srcset="/blog/images/default4_hu11774824972063855820.webp" type="image/webp" />
      <img src="/blog/images/default4.jpg" alt="/images/default4.jpg" />
    </picture>
    
  </figure>
  

  <div class="card-body">
    <h2 class="card-title">関数が上に凸であることの必要十分条件はヘッセ行列が半負定値の証明</h2>

    <p class="date text-base-content/60">
    
      水曜日, 3月 11, 2020
    
    </p>

    本記事はQrunchからの転載です。
関数が上に凸であることの必要十分条件はヘッセ行列が半負定値であることです。ネット上だと日本語でまとまっている文献があんまりないかもと思ったので、今回はこの証明をまとめます。 なお、関数が下に凸のときにはヘッセ行列は半正定値となります。上に凸の定義を使っているところを下に凸の定義に置き換え、正定値を負定値に置き換えれば、同じ議論が可能です。 また出てくる関数$f$は暗黙的に定義域で2階微分可能としています。
定義 関数が上に凸の定義 関数$f:\mathbb{R}^{n} \rightarrow \mathbb{R}$が上に凸とは任意の元$\mathbf{x}^{(1)}, \mathbf{x}^{(2)} \in \mathbb{R}^{n}$と任意の$t \in [0,1]$に対して以下が成り立つことを指します。 $$ f(t\mathbf{x}^{(2)} + (1 -t)\mathbf{x}^{(1)}) \geq tf(\mathbf{x}^{(2)}) + (1 -t) f(\mathbf{x}^{(1)}).$$
ヘッセ行列の定義 関数$f:\mathbb{R}^{n} \rightarrow \mathbb{R}$のヘッセ行列$H$を以下のように定義します。 $$H_f = \nabla^2 f = \begin{pmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp;\frac{\partial^2 f}{\partial x_1\partial x_2} &amp; \dots &amp; \frac{\partial^2 f}{\partial x_1\partial x_n} \cr \frac{\partial^2 f}{\partial x_2\partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \dots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \cr \vdots &amp; \vdots &amp; \ddots &amp; \vdots \cr \frac{\partial^2 f}{\partial x_n\partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \dots &amp; \frac{\partial^2 f}{ \partial x_n^2} \end{pmatrix}.

    <div class="card-actions justify-between items-center mt-4">
      <div class="flex items-center">
  
  <span>@</span>
  

  <span itemprop="author" itemscope itemtype="https://schema.org/Person">
  
    <span itemprop="name"></span>
  
  </span>
</div>


      <div class="inline-flex items-center">
        <ion-icon name="time" class="mr-1"></ion-icon>
        <span>3分で読めます</span>
      </div>
    </div>
  </div>
</a>

      </div>
    
    </div>
    

    
    <div class="flex justify-center pt-8">
      <div class="join grid grid-cols-2">
  
  <a href="/blog/categories/page/5/" title=前へ class="join-item btn btn-outline btn-sm">
    前へ
  </a>
  
  
  <a href="/blog/categories/page/7/" title="次へ" class="join-item btn btn-outline btn-sm">
    次へ
  </a>
  
</div>

    </div>
    
  </div>
</div>



            
            <footer class="flex justify-between items-center gap-2 px-4 py-12">
            
              <div>
  
  <p>© 2024 MatLoverによるMatlab以外のブログ</p>
  

  
  <p class="text-sm">
    🌱
    <span class="text-base-content/60">
      Powered by <a class="hover:underline" href="https://gohugo.io/" target="_blank">Hugo</a> with theme
      <a class="hover:underline" href="https://github.com/g1eny0ung/hugo-theme-dream" target="_blank">Dream</a>.</span
    >
  </p>
  
</div>

              <div
  x-data="{ icons: [
    { name: 'moon', status: 'y' },
    { name: 'sunny', status: 'n' },
    { name: 'desktop', status: 'auto' }
  ] }"
  class="flex items-center h-[32px] px-2 gap-2 border border-base-300 rounded-full"
>
  <template x-for="icon in icons">
    <div
      role="button"
      tabindex="0"
      :aria-label="'Select ' + icon.name + ' mode'"
      class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary"
      :class="$store.darkMode.icon() === icon.name && 'bg-primary'"
      @click="$store.darkMode.toggle(icon.status)"
    >
      <ion-icon
        :name="`${icon.name}-outline`"
        class="group-hover:text-primary-content"
        :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"
      >
      </ion-icon>
    </div>
  </template>
</div>

            </footer>
          </div>
        </div>
        <div class="back">
          <div class="container">
            
            <div class="dream-grid">
  

  

  
</div>

            
          </div>
        </div>
      </div>
    </div>

    <script>
  window.lightTheme =  null 
  window.darkTheme =  null 
</script>

<script src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
<script src="/blog/js/grid.js"></script>

<script src="/blog/js/main.js"></script>

    





    

    
    
  
    
      
    
  


    

    <script type="module" src="https://unpkg.com/ionicons@7.4.0/dist/ionicons/ionicons.esm.js"></script>
    <script nomodule src="https://unpkg.com/ionicons@7.4.0/dist/ionicons/ionicons.js"></script>
  </body>
</html>
