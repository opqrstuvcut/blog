<!DOCTYPE html>
<html lang="ja" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Posts | MatLoverによるMatlab以外のブログ</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - MatLoverによるMatlab以外のブログ">
<meta name="author" content="">
<link rel="canonical" href="https://opqrstuvcut.github.io/blog/post/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://opqrstuvcut.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://opqrstuvcut.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://opqrstuvcut.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://opqrstuvcut.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://opqrstuvcut.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://opqrstuvcut.github.io/blog/post/index.xml">
<link rel="alternate" hreflang="ja" href="https://opqrstuvcut.github.io/blog/post/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  
    
      
    
  

<meta property="og:title" content="Posts" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://opqrstuvcut.github.io/blog/post/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Posts"/>
<meta name="twitter:description" content=""/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://opqrstuvcut.github.io/blog/post/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://opqrstuvcut.github.io/blog/" accesskey="h" title="MatLoverによるMatlab以外のブログ (Alt + H)">MatLoverによるMatlab以外のブログ</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://opqrstuvcut.github.io/blog/" title="Home">
                    <span>homeHome</span>
                </a>
            </li>
            <li>
                <a href="https://opqrstuvcut.github.io/blog/archives" title="Archives">
                    <span>archivesArchives</span>
                </a>
            </li>
            <li>
                <a href="https://opqrstuvcut.github.io/blog/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>searchSearch</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">TensorBoardのDocker Image
    </h2>
  </header>
  <div class="entry-content">
    <p>たまにTensorBoardを使うときに、ホスト環境などにTensorBoardを入れるより、それ用のコンテナをたてたくなったので、そのメモです。
Docker Imageは以下のとおり。
FROM python:3.8 RUN pip install tensorflow WORKDIR /logs ENTRYPOINT [&#34;tensorboard&#34;, &#34;--logdir&#34;, &#34;/logs&#34;, &#34;--host&#34;, &#34;0.0.0.0&#34;] 次のような感じでdocker buildとdocker runします。
$ docker build -t tensorboard . $ docker run -it --rm -p 10000:6006 -v $PWD/logs:/logs tensorboard -vに指定するhost側のlogのディレクトリのパスと-pに指定するportは適当に変更する。</p>
  </div>
  <footer class="entry-footer"><span title='2020-11-18 00:00:00 +0000 UTC'>11月 18, 2020</span></footer>
  <a class="entry-link" aria-label="post link to TensorBoardのDocker Image" href="https://opqrstuvcut.github.io/blog/posts/tensorboard%E3%81%AEdocker-image/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">docker-composeのbuildがはじまらないとき
    </h2>
  </header>
  <div class="entry-content">
    <p>最近では実験用の環境なんかもDockerコンテナ上に用意することも多いです。
docker-composeも使うわけですが、たまにdocker-composeのbuildがいつになってもはじまらないことがあります。
Building xxxがずっと表示されて、そこから進まないわけです。
以前も同じケースに出くわしたのにすぐ思い出せなかったので、備忘録的に残りしておきます（似た記事はネットにたくさんありますが）。
docker-composeのbuildがはじまらない原因 学習に使うデータのように重いファイルを置いてあるディレクトリでdocker-composeをおこなうのが原因です。
なぜこれが原因でbuildがはじまらないかといえば、Docker Imageのbuildをするときに、Dockerfileがあるディレクトリ上のデータはすべてDockerのデーモンに渡されるためです。
全部のファイルをデーモンに渡そうとするので、学習データなんかがDockerfileと同じディレクトリ上にあると、それらの重たいファイルも渡そうとしてしまい、いつになってもbuildが進まないわけですね。
対処方法 .dockerignoreにデーモンに渡してほしくないディレクトリ、ファイルを指定する ファイルパスを工夫する（でもdockerignoreを使うのが一番いいんじゃないでしょうか） </p>
  </div>
  <footer class="entry-footer"><span title='2020-11-08 00:00:00 +0000 UTC'>11月 8, 2020</span></footer>
  <a class="entry-link" aria-label="post link to docker-composeのbuildがはじまらないとき" href="https://opqrstuvcut.github.io/blog/posts/docker-compose%E3%81%AEbuild%E3%81%8C%E3%81%AF%E3%81%98%E3%81%BE%E3%82%89%E3%81%AA%E3%81%84%E3%81%A8%E3%81%8D/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">GPUサーバーでのTensorFlow &#43; uWSGIでFailed to get device properties, error code: 3
    </h2>
  </header>
  <div class="entry-content">
    <p>GPUサーバー上でTensorFlowを動かすアプリを作成し、nginxとの間にはuWSGIを挟む構成にしていたところ、次のエラーが出てしまいました。
Failed to get device properties, error code: 3 他の記事の引用になってしまいますが、エラーメッセージ自体をググっても解決できなかったので、メモ程度に載せておきます。
原因 確かとは断言できないのですが、次の記事にかかれていることが怪しいと推測しました。 https://keng000.hatenablog.com/entry/2020/05/05/092425
つまり、マルチスレッドでのモデルの読み込み方が良くないのかと。
対処 記事に書かれている通り、uWSGIのiniファイルで次のように追記しました。
[uwsgi] lazy-apps = true とりあえずこれで解決しました。</p>
  </div>
  <footer class="entry-footer"><span title='2020-11-08 00:00:00 +0000 UTC'>11月 8, 2020</span></footer>
  <a class="entry-link" aria-label="post link to GPUサーバーでのTensorFlow &#43; uWSGIでFailed to get device properties, error code: 3" href="https://opqrstuvcut.github.io/blog/posts/gpu%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%81%A7%E3%81%AEtensorflow--uwsgi%E3%81%A7failed-to-get-device-properties-error-code-3/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">動画データから前景と背景を分離する
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
画像から前景と背景を分けるのは以前に取り上げたのですが、動画でもOpenCVで前景と背景をわけることが可能です。ここでいう前景は動いている物体を指します。
前景と背景を分離する難しさ 動画から前景と背景を分離するアルゴリズムを自分で実装するのは結構大変です。 最も単純なアルゴリズムは背景だけが写っている画像を撮っておいて、運用時には背景画像とリアルタイムに取得された画像との差分を取るというのが考えられます。 ただしこのやり方だと照明環境は一定にしないといけないのですが、問題設定によってはそうできなかったりします。また背景だけの画像を撮るのが難しい場合もあります。
問題の難しさから、リッチな処理をしたくなるのですが、変に処理をすると計算時間が伸びていく可能性もあります。
OpenCVでやってみる OpenCVのBackgroundSubtractorMOG2を使うと、簡単に照明の変化にも適応する手法を利用できます。背景画像を撮る必要もありません。 BackgroundSubtractorMOG2では背景と前景を分離するために混合ガウス分布を利用しています。 混合ガウス分布の学習はいつするの？という話ですが、これはリアルタイムに更新されていきます。リアルタイムで更新するので照明変化などにも対応できるわけですね。
今回のテスト用の動画としてこちらを利用させていただきました。 道路を車がビュンビュン走っています。
次のようにしてBackgroundSubtractorMOG2を利用できます。
import cv2 import numpy as np cap = cv2.VideoCapture(&#34;ex.mp4&#34;) fgbg = cv2.createBackgroundSubtractorMOG2(history=60, detectShadows=False) masks = [] kernel = np.ones((5, 5), np.uint8) while True: ret, frame = cap.read() if not ret: break fgmask = fgbg.apply(frame) fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel) masks.append(fgmask) cap.release() cv2.destroyAllWindows() createBackgroundSubtractorMOG2に渡している引数ですが、history=60とすることで、直近の60フレームだけをモデルに考慮させているようなイメージです（正確にそうなるわけではないはずですが）。 また、detectShadows=Trueの場合には影も検出できるのですが、不要なのでFalseにしています。この機能を切っておいたほうが少し早くなります。
fgbg.apply(frame)の返り値が前景の検出結果（mask画像）になります。 ちなみに、検出された結果にオープニング処理を入れてノイズを減らしています。今回の動画ではオープニング処理を入れないと次のように結構ノイズが拾われてしまいます。
検出されたマスクにオープニング処理も入れた結果が次のとおりです（GIFが動かない場合はクリックしてみてください）。
コード全体 import cv2 import numpy as np cap = cv2....</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-20 11:04:00 +0900 JST'>8月 20, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 動画データから前景と背景を分離する" href="https://opqrstuvcut.github.io/blog/posts/%E5%8B%95%E7%94%BB%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8B%E3%82%89%E5%89%8D%E6%99%AF%E3%81%A8%E8%83%8C%E6%99%AF%E3%82%92%E5%88%86%E9%9B%A2%E3%81%99%E3%82%8B/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">connectedComponentsで連結した領域の取得
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
OpenCVでは二値画像から結合している領域の抽出をおこなうことができます。 こういうのは自分で実装すると大変なので、大変助かりますね。
connectedComponets 次の二値画像を考えます。 領域として取り出したいのは2つの白い部分です。
connectedComponetsを使って簡単にこの2つの領域を抽出できます。
n_labels, labels = cv2.connectedComponents(bi_img) n_labelsはラベル付けされた領域の数です。 labelsには入力画像と同じサイズの行列が入っており、それぞれの座標の値がその位置での領域のラベルをあらわします。
ラベルごとに色付けしてみると、次のようになります。
colored_img = np.zeros(bi_img.shape &#43; (3,), dtype=np.uint8) for i in range(1, n_labels): colored_img[labels == i] = [np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256)] plt.imshow(colored_img) plt.show() </p>
  </div>
  <footer class="entry-footer"><span title='2020-08-18 11:00:00 +0900 JST'>8月 18, 2020</span></footer>
  <a class="entry-link" aria-label="post link to connectedComponentsで連結した領域の取得" href="https://opqrstuvcut.github.io/blog/posts/connectedcomponents%E3%81%A7%E9%80%A3%E7%B5%90%E3%81%97%E3%81%9F%E9%A0%98%E5%9F%9F%E3%81%AE%E5%8F%96%E5%BE%97/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">抽出した輪郭の描画
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
OpenCVのfindContoursで見つけた輪郭はdrawContoursで簡単に描画できます。 次のようにして使えます。
drawed = cv2.drawContours(img, contours=contours, contourIdx=-1, color=(255, 0, 0), thickness=10, lineType=8, hierarchy=hierarcies, maxLevel=1) 引数の意味はそれぞれ次のとおりです。必須なのはcolorまでです。
引数 意味 contours findContoursで見つかった輪郭 contourIdx 描画する輪郭のインデックスを指定する（-1だと全て描画） color 描画する輪郭の色 thickness 描画する輪郭の太さ lineType 4、8、cv2.LINE_AAのどれかを指定し、後のほうがきれいに描画される hierarchy findContoursで見つかった輪郭の階層構造 maxLevel 描画する最大の階層を指定する maxLevelを1にしたときと、2にしたときの違いを次に示します。
maxLevel=1 maxLevel=2 maxLevelが2のときには外側の輪郭の中まで輪郭が描画されていますね。</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-17 11:03:00 +0900 JST'>8月 17, 2020</span></footer>
  <a class="entry-link" aria-label="post link to 抽出した輪郭の描画" href="https://opqrstuvcut.github.io/blog/posts/%E6%8A%BD%E5%87%BA%E3%81%97%E3%81%9F%E8%BC%AA%E9%83%AD%E3%81%AE%E6%8F%8F%E7%94%BB/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">findContoursで輪郭の検出
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
画像から物体の輪郭を見つけたくなることが多々あります。 そんなときにもOpenCVを利用することができます。
findContoursで輪郭抽出 次の画像から輪郭の抽出をおこなうことを考えます。
最初に次のように二値化しておきます。
_, bi_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY &#43; cv2.THRESH_OTSU) これに対して次のようにfindContoursを適用します。
contours, hierarcies = cv2.findContours(bi_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) 第二引数は輪郭の取り出し方を指定しており、cv2.RETR_EXTERNALは一番外側の輪郭だけを取り出します。ここに指定できる方法の比較は後でおこないます。 第三引数は輪郭の近似方法をあらわします。例えば、cv2.CHAIN_APPROX_SIMPLEにすると、返ってくる点の数が大きく減ります。cv2.CHAIN_APPROX_TC89_L1にすると返ってくる点の数をうまい具合に減らしてくれますが、他に比べると計算量がかかります。 返り値の1つめが輪郭を格納したリストです。２つめが輪郭の階層構造をあらわしています。 細かく言うと、輪郭の方は、点のリストが1つの輪郭をあらわし、それらのリストが格納されています。 階層構造の方は、輪郭ごとに１つの階層構造をあらわす4つの要素をもつリストが存在します。各要素の0番目は次の輪郭のインデックス、1番目は前の輪郭のインデックス、2番目は子の輪郭のなかで1番目のインデックス、3番目は親の輪郭のインデックスをあらわします。親と子が何かといえば、親はみている輪郭を囲んでいる輪郭のことで、子は中にある輪郭のことです。 見つかった輪郭を次のように描画してみます。
drawed = cv2.drawContours(np.stack([img, img, img], axis=-1), contours, -1, (255, 0, 0), 10) plt.imshow(drawed) plt.show() 描画の結果は以下のとおりです。
輪郭の取り出し方を変えてみる 先程は輪郭の取り出し方にcv2.RETR_EXTERNALを指定しました。これは一番外側の輪郭しか取れません。 次にちゃんと階層構造をもった結果を返すようにしてみます。これにはcv2.RETR_TREEを指定します。
contours, hierarcies = cv2.findContours(bi_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) 他にもcv2.RETR_LISTやcv2.RETR_CCOMPなどがありますが、hierarciesの中の階層構造の情報の持ち方が変わってきます。</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-16 17:56:36 +0900 JST'>8月 16, 2020</span></footer>
  <a class="entry-link" aria-label="post link to findContoursで輪郭の検出" href="https://opqrstuvcut.github.io/blog/posts/findcontours%E3%81%A7%E8%BC%AA%E9%83%AD%E3%81%AE%E6%A4%9C%E5%87%BA/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">テンプレートマッチングで画像から物体をみつける
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
カメラを固定しておいて、何らかの被写体を取り続けるということはよくある問題設定です。 ただし、被写体の位置が毎回少しズレるということも多々あります。 そんなときにテンプレートマッチングを使うことができます。
テンプレートマッチングについて テンプレートマッチングではテンプレート画像と呼ばれるものを事前に用意しておきます。 そして、検出したいものが写っている画像の左上の領域から順にテンプレート画像とどれくらい似ているかを計算していきます。 このようにして、テンプレート画像とよく似た領域を検出するというのがテンプレートマッチングです。
OpenCVでテンプレートマッチング 次の左の画像をテンプレート画像として、右から同じ物体を検出してみます。
テンプレートマッチングは次のようにしておこなえます。
res = cv2.matchTemplate(img, template, cv2.TM_CCORR_NORMED) cv2.TM_CCORR_NORMEDは類似度の計算の方法です。 選択肢は複数あり、手法によって精度と計算時間が変わります。 詳細はこちらをご確認ください。
返り値には各位置での類似度が格納されています。
TM_CCORR_NORMEDの場合には大きな値ほど、似ていますので明るい部分がもっともテンプレートとマッチしたことをあらわします。
この部分の画像を次のように切り抜いてみます。
_, max_val, _, max_loc = cv2.minMaxLoc(res) height, width = template.shape plt.imshow(img[max_loc[1]: max_loc[1] &#43; height, max_loc[0]: max_loc[0] &#43; width]) plt.show() 結果は以下のとおりです。 バッチリできていることがわかります。</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-15 11:09:00 +0900 JST'>8月 15, 2020</span></footer>
  <a class="entry-link" aria-label="post link to テンプレートマッチングで画像から物体をみつける" href="https://opqrstuvcut.github.io/blog/posts/%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%83%9E%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%8B%E3%82%89%E7%89%A9%E4%BD%93%E3%82%92%E3%81%BF%E3%81%A4%E3%81%91%E3%82%8B/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">minMaxLocで最大と最小の位置を楽に取得
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
行列の最大値、最小値はNumPyのmaxやmin、またそれらのインデックスはargmaxやargminを使えば取得できるのですが、OpenCVでは一発ですべて取得できます。
min_val, max_val, min_idx, max_idx = cv2.minMaxLoc(np.array([[1, 2, 3], [4, 5, 6]])) print(min_val, max_val, min_idx, max_idx) この出力は以下のとおりですが、それぞれ最小値、最大値、最小値の位置、最大値の位置をあらわします。位置は$(x,y)$をあらわしていますので、行列でいえば、（列、行）の順に格納されています。
(1.0, 6.0, (0, 0), (2, 1)) </p>
  </div>
  <footer class="entry-footer"><span title='2020-08-11 11:04:00 +0900 JST'>8月 11, 2020</span></footer>
  <a class="entry-link" aria-label="post link to minMaxLocで最大と最小の位置を楽に取得" href="https://opqrstuvcut.github.io/blog/posts/minmaxloc%E3%81%A7%E6%9C%80%E5%A4%A7%E3%81%A8%E6%9C%80%E5%B0%8F%E3%81%AE%E4%BD%8D%E7%BD%AE%E3%82%92%E6%A5%BD%E3%81%AB%E5%8F%96%E5%BE%97/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">compHistでヒストグラム比較をいろいろなやり方でおこなう
    </h2>
  </header>
  <div class="entry-content">
    <p>本記事はQrunchからの転載です。
画像処理の領域では画像から特徴量をあらわすヒストグラムを生成することがよくあります。 特徴量としてヒストグラムを生成するということは、比較をすることもよくあるということで、今回はヒストグラムの比較を扱います。
compHistによるヒストグラムの比較の仕方 次のようにしてヒストグラムの比較をおこないます。
cv2.compareHist(hist_1, hist_2, method) hist_1とhist_2はヒストグラムをあらわすNumPy arrayです。 methodは比較方法をあらわし、以下のようなものがあります。
方法 概要 cv2.HISTCMP_CORREL ピアソンの相関係数 cv2.HISTCMP_CHISQR カイ二乗検定 cv2.HISTCMP_KL_DIV KLダイバージェンス cv2.HISTCMP_INTERSECT 交差法 cv2.HISTCMP_BHATTACHARYYA バタチャリア距離 それぞれの違いは式を見ればわかるという話もありますが、ぱっと分かるように数値的な違いを見ていきます。
比較方法の一覧 次のようなヒストグラムを対象にして各比較方法の違いをみてみます。 結果は次のとおりです。
比較方法 2と2 1と2 2と1 2と3 1と3 HISTCMP_CORREL 1.0 0.22 0.22 -0.22 -0.87 HISTCMP_CHISQR 0.0 10.13 9.11 11.78 18.0 HISTCMP_KL_DIV 0.0 245.6 228.07 234.31 447.40 HISTCMP_INTERSECT 18.0 8.0 8.0 4.0 0.0 HISTCMP_BHATTACHARYYA 0.0 0.73 0.73 0.82 1.0 手法によって、完全一致は大きい値になるのか、小さい値になるのか、また最大値と最小値はあるのかといったところも違うので、注意が必要です。
なお、利用したコードは以下のとおりです。
import numpy as np import pandas as pd import matplotlib....</p>
  </div>
  <footer class="entry-footer"><span title='2020-08-10 13:20:47 +0900 JST'>8月 10, 2020</span></footer>
  <a class="entry-link" aria-label="post link to compHistでヒストグラム比較をいろいろなやり方でおこなう" href="https://opqrstuvcut.github.io/blog/posts/comphist%E3%81%A7%E3%83%92%E3%82%B9%E3%83%88%E3%82%B0%E3%83%A9%E3%83%A0%E6%AF%94%E8%BC%83%E3%82%92%E3%81%84%E3%82%8D%E3%81%84%E3%82%8D%E3%81%AA%E3%82%84%E3%82%8A%E6%96%B9%E3%81%A7%E3%81%8A%E3%81%93%E3%81%AA%E3%81%86/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="https://opqrstuvcut.github.io/blog/post/page/2/">
      «&nbsp;前へ&nbsp;
    </a>
    <a class="next" href="https://opqrstuvcut.github.io/blog/post/page/4/">次へ&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://opqrstuvcut.github.io/blog/">MatLoverによるMatlab以外のブログ</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
